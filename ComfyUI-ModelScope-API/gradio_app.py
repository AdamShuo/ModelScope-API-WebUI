import gradio as gr
import requests
import json
import time
import numpy as np
from PIL import Image
from io import BytesIO
import base64
import tempfile
import os
import random
import hashlib

try:
    from cryptography.fernet import Fernet
    CRYPTO_AVAILABLE = True
except ImportError:
    print("âš ï¸ è­¦å‘Š: æœªå®‰è£…cryptographyåº“ï¼Œå°†ä½¿ç”¨ç®€å•ç¼–ç ä¿å­˜API Token")
    print("å»ºè®®è¿è¡Œ: pip install cryptography")
    CRYPTO_AVAILABLE = False
    Fernet = None

try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    print("âš ï¸ è­¦å‘Š: æœªå®‰è£…openaiåº“ï¼Œæ–‡æœ¬å¯¹è¯å’Œå›¾ç”Ÿæ–‡åŠŸèƒ½å°†ä¸å¯ç”¨")
    print("è¯·è¿è¡Œ: pip install openai")
    OPENAI_AVAILABLE = False
    OpenAI = None

# API Token åŠ å¯†ä¿å­˜å’Œè¯»å–åŠŸèƒ½
def get_encryption_key():
    """ç”Ÿæˆæˆ–è·å–åŠ å¯†å¯†é’¥"""
    key_file = os.path.join(os.path.dirname(__file__), '.token_key')
    
    if os.path.exists(key_file):
        with open(key_file, 'rb') as f:
            return f.read()
    else:
        # åŸºäºæœºå™¨ç‰¹å¾ç”Ÿæˆå¯†é’¥
        machine_id = hashlib.sha256(
            (os.getcwd() + str(os.path.getsize(__file__))).encode()
        ).digest()[:32]
        
        if CRYPTO_AVAILABLE:
            key = Fernet.generate_key()
        else:
            # ç®€å•çš„base64ç¼–ç ä½œä¸ºå¤‡é€‰
            key = base64.b64encode(machine_id)
        
        with open(key_file, 'wb') as f:
            f.write(key)
        
        return key

def save_api_token(token):
    """ä¿å­˜API Tokenåˆ°åŠ å¯†æ–‡ä»¶"""
    if not token or not token.strip():
        return False
    
    try:
        token_file = os.path.join(os.path.dirname(__file__), '.api_token')
        key = get_encryption_key()
        
        if CRYPTO_AVAILABLE:
            # ä½¿ç”¨FernetåŠ å¯†
            fernet = Fernet(key)
            encrypted_token = fernet.encrypt(token.encode())
        else:
            # ç®€å•çš„base64ç¼–ç 
            encrypted_token = base64.b64encode(token.encode())
        
        with open(token_file, 'wb') as f:
            f.write(encrypted_token)
        
        print("âœ… API Tokenå·²ä¿å­˜åˆ°æœ¬åœ°åŠ å¯†æ–‡ä»¶")
        return True
        
    except Exception as e:
        print(f"âŒ ä¿å­˜API Tokenå¤±è´¥: {e}")
        return False

def load_api_token():
    """ä»åŠ å¯†æ–‡ä»¶è¯»å–API Token"""
    try:
        token_file = os.path.join(os.path.dirname(__file__), '.api_token')
        
        if not os.path.exists(token_file):
            return ""
        
        key = get_encryption_key()
        
        with open(token_file, 'rb') as f:
            encrypted_token = f.read()
        
        if CRYPTO_AVAILABLE:
            # ä½¿ç”¨Fernetè§£å¯†
            fernet = Fernet(key)
            token = fernet.decrypt(encrypted_token).decode()
        else:
            # ç®€å•çš„base64è§£ç 
            token = base64.b64decode(encrypted_token).decode()
        
        return token
        
    except Exception as e:
        print(f"âš ï¸ è¯»å–API Tokenå¤±è´¥: {e}")
        return ""

def delete_api_token():
    """åˆ é™¤ä¿å­˜çš„API Token"""
    try:
        token_file = os.path.join(os.path.dirname(__file__), '.api_token')
        key_file = os.path.join(os.path.dirname(__file__), '.token_key')
        
        if os.path.exists(token_file):
            os.remove(token_file)
        if os.path.exists(key_file):
            os.remove(key_file)
        
        print("âœ… API Tokenå·²åˆ é™¤")
        return True
        
    except Exception as e:
        print(f"âŒ åˆ é™¤API Tokenå¤±è´¥: {e}")
        return False

# è·å–å›¾åƒå°ºå¯¸ä¿¡æ¯
def get_image_info(image):
    if image is None:
        return "æ— å›¾åƒ"
    
    if hasattr(image, 'size'):  # PIL Image
        width, height = image.size
        return f"å°ºå¯¸: {width} Ã— {height} åƒç´ "
    elif hasattr(image, 'shape'):  # numpy array
        if len(image.shape) == 3:
            height, width = image.shape[:2]
        else:
            height, width = image.shape
        return f"å°ºå¯¸: {width} Ã— {height} åƒç´ "
    else:
        return "æ— æ³•è·å–å°ºå¯¸ä¿¡æ¯"

# åŠ è½½é…ç½®æ–‡ä»¶
def load_config():
    config_path = os.path.join(os.path.dirname(__file__), 'modelscope_config.json')
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except:
        return {
            "default_model": "Qwen/Qwen-Image",
            "timeout": 720,
            "image_download_timeout": 30,
            "default_prompt": "A beautiful landscape"
        }

# å¸¦æœ‰é‡è¯•æœºåˆ¶çš„APIè¯·æ±‚å‡½æ•°
def make_api_request_with_retry(url, headers, data=None, timeout=60, max_retries=3, base_delay=2, method='post'):
    for attempt in range(max_retries):
        try:
            if method.lower() == 'get':
                response = requests.get(url, headers=headers, timeout=timeout)
            else:
                response = requests.post(url, data=data, headers=headers, timeout=timeout)
            
            if response.status_code == 429:
                retry_after = response.headers.get('Retry-After')
                wait_time = int(retry_after) if retry_after else base_delay * (2 ** attempt)
                print(f"Rate limited. Waiting {wait_time} seconds before retry...")
                time.sleep(wait_time)
                continue
            
            return response
            
        except requests.exceptions.Timeout:
            if attempt < max_retries - 1:
                wait_time = base_delay * (2 ** attempt)
                print(f"Request timeout. Retrying in {wait_time} seconds...")
                time.sleep(wait_time)
                continue
            else:
                print("Max retries reached. Request failed.")
                return None
        except Exception as e:
            if attempt < max_retries - 1:
                wait_time = base_delay * (2 ** attempt)
                print(f"Request failed: {e}. Retrying in {wait_time} seconds...")
                time.sleep(wait_time)
                continue
            else:
                print(f"Max retries reached. Final error: {e}")
                return None
    
    return None

# è®¡ç®—è‡ªé€‚åº”å°ºå¯¸
def calculate_adaptive_size(image, long_edge):
    if hasattr(image, 'shape'):  # numpy array
        h, w = image.shape[:2]
    else:  # PIL Image
        w, h = image.size
    
    # è®¡ç®—æ¯”ä¾‹
    if w >= h:  # å®½å›¾
        new_w = long_edge
        new_h = int(h * long_edge / w)
    else:  # é«˜å›¾
        new_h = long_edge
        new_w = int(w * long_edge / h)
    
    # ç¡®ä¿å°ºå¯¸æ˜¯64çš„å€æ•°
    new_w = ((new_w + 31) // 64) * 64
    new_h = ((new_h + 31) // 64) * 64
    
    return new_w, new_h

# å›¾åƒç¼–è¾‘åŠŸèƒ½
def edit_image(api_token, model, image, prompt, negative_prompt, adaptive_ratio, width, height, long_edge, steps, guidance, seed):
    config = load_config()
    
    if not api_token:
        return None, "è¯·æä¾›æœ‰æ•ˆçš„API Token"
    
    if image is None:
        return None, "è¯·å…ˆä¸Šä¼ å›¾åƒ"
    
    try:
        # è½¬æ¢ä¸Šä¼ çš„å›¾ç‰‡ä¸ºbase64
        if hasattr(image, 'shape'):  # numpy array
            pil_image = Image.fromarray(image.astype('uint8'))
        else:  # PIL Image
            pil_image = image
        
        # æ ¹æ®è‡ªé€‚åº”æ¯”ä¾‹é€‰é¡¹è®¡ç®—æœ€ç»ˆå°ºå¯¸
        if adaptive_ratio:
            final_width, final_height = calculate_adaptive_size(image, long_edge)
        else:
            final_width, final_height = width, height
        
        # ä¿å­˜å›¾åƒåˆ°ä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as tmp_file:
            pil_image.save(tmp_file.name, format='JPEG')
            temp_img_path = tmp_file.name
        
        # ä¸Šä¼ å›¾ç‰‡åˆ°ä¸´æ—¶CDNè·å–URL
        upload_url = 'https://ai.kefan.cn/api/upload/local'
        
        try:
            with open(temp_img_path, 'rb') as img_file:
                files = {'file': img_file}
                upload_response = requests.post(upload_url, files=files)
        finally:
            # ç¡®ä¿æ–‡ä»¶å¥æŸ„å…³é—­åå†åˆ é™¤
            try:
                os.unlink(temp_img_path)
            except:
                pass
        
        if upload_response.status_code != 200:
            return None, f"å›¾ç‰‡ä¸Šä¼ å¤±è´¥: {upload_response.text}"
        
        upload_data = upload_response.json()
        if not upload_data.get('success'):
            return None, f"å›¾ç‰‡ä¸Šä¼ å¤±è´¥: {upload_data.get('message', 'Unknown error')}"
        
        image_url = upload_data['data']
        
        # æ„å»ºAPIè¯·æ±‚
        payload = {
            'model': model,
            'prompt': prompt,
            'image_url': image_url,
            'size': f"{final_width}x{final_height}",
            'steps': steps,
            'guidance': guidance,
            'seed': seed
        }
        
        if negative_prompt.strip():
            payload['negative_prompt'] = negative_prompt
        
        url = 'https://api-inference.modelscope.cn/v1/images/generations'
        
        headers = {
            'Authorization': f'Bearer {api_token}',
            'Content-Type': 'application/json',
            'X-ModelScope-Async-Mode': 'true'
        }
        
        # å‘é€APIè¯·æ±‚
        response = make_api_request_with_retry(
            url=url,
            headers=headers,
            data=json.dumps(payload),
            timeout=int(config.get("timeout", 720)),
            max_retries=2,
            base_delay=3,
            method='post'
        )
        
        if not response:
            return None, "APIè¯·æ±‚å¤±è´¥: ç½‘ç»œè¿æ¥é—®é¢˜"
        
        if response.status_code != 200:
            return None, f"APIè¯·æ±‚å¤±è´¥: {response.status_code}, {response.text}"
        
        task_data = response.json()
        if 'task_id' not in task_data:
            return None, f"APIå“åº”æ ¼å¼é”™è¯¯: {task_data}"
        
        task_id = task_data['task_id']
        print(f"ä»»åŠ¡å·²æäº¤ï¼Œä»»åŠ¡ID: {task_id}")
        
        # è½®è¯¢ä»»åŠ¡çŠ¶æ€
        max_wait_seconds = max(60, int(config.get('timeout', 720)))
        start_time = time.time()
        check_interval = 3
        
        while time.time() - start_time < max_wait_seconds:
            time.sleep(check_interval)
            
            status_response = make_api_request_with_retry(
                url=f'https://api-inference.modelscope.cn/v1/tasks/{task_id}',
                headers={
                    'Authorization': f'Bearer {api_token}',
                    'X-ModelScope-Task-Type': 'image_generation'
                },
                method='get',
                timeout=int(config.get("timeout", 720))
            )
            
            if not status_response:
                continue
                
            if status_response.status_code != 200:
                continue
                
            status_data = status_response.json()
            status = status_data.get('task_status')
            
            if status == 'SUCCEED':
                output_images = status_data.get('output_images', [])
                if not output_images:
                    return None, "ä»»åŠ¡æˆåŠŸä½†æ— è¾“å‡ºå›¾åƒ"
                
                # ä¸‹è½½ç”Ÿæˆçš„å›¾ç‰‡
                img_url = output_images[0]
                img_response = requests.get(img_url, timeout=int(config.get("image_download_timeout", 30)))
                
                if img_response.status_code == 200:
                    img_data = BytesIO(img_response.content)
                    result_image = Image.open(img_data)
                    return result_image, f"å›¾åƒç¼–è¾‘æˆåŠŸï¼ä»»åŠ¡ID: {task_id}, å°ºå¯¸: {final_width}x{final_height}"
                else:
                    return None, f"å›¾ç‰‡ä¸‹è½½å¤±è´¥: {img_response.status_code}"
            
            elif status == 'FAILED':
                error_info = status_data.get('errors', {})
                return None, f"ä»»åŠ¡å¤±è´¥: {error_info.get('message', 'Unknown error')}"
            
            elif status == 'PENDING' or status == 'RUNNING':
                continue
        
        return None, "ä»»åŠ¡è½®è¯¢è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•"
        
    except Exception as e:
        return None, f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"

# æ–‡ç”Ÿå›¾åŠŸèƒ½
def generate_image(api_token, model, prompt, negative_prompt, width, height, steps, guidance, seed):
    config = load_config()
    
    if not api_token:
        return None, "è¯·æä¾›æœ‰æ•ˆçš„API Token"
    
    try:
        payload = {
            'model': model,
            'prompt': prompt,
            'size': f"{width}x{height}",
            'steps': steps,
            'guidance': guidance,
            'seed': seed
        }
        
        if negative_prompt.strip():
            payload['negative_prompt'] = negative_prompt
        
        url = 'https://api-inference.modelscope.cn/v1/images/generations'
        
        headers = {
            'Authorization': f'Bearer {api_token}',
            'Content-Type': 'application/json',
            'X-ModelScope-Async-Mode': 'true'
        }
        
        response = make_api_request_with_retry(
            url=url,
            headers=headers,
            data=json.dumps(payload),
            timeout=int(config.get("timeout", 720)),
            max_retries=2,
            base_delay=3,
            method='post'
        )
        
        if not response:
            return None, "APIè¯·æ±‚å¤±è´¥: ç½‘ç»œè¿æ¥é—®é¢˜"
        
        if response.status_code != 200:
            return None, f"APIè¯·æ±‚å¤±è´¥: {response.status_code}, {response.text}"
        
        task_data = response.json()
        if 'task_id' not in task_data:
            return None, f"APIå“åº”æ ¼å¼é”™è¯¯: {task_data}"
        
        task_id = task_data['task_id']
        print(f"ä»»åŠ¡å·²æäº¤ï¼Œä»»åŠ¡ID: {task_id}")
        
        # è½®è¯¢ä»»åŠ¡çŠ¶æ€
        max_wait_seconds = max(60, int(config.get('timeout', 720)))
        start_time = time.time()
        check_interval = 3
        
        while time.time() - start_time < max_wait_seconds:
            time.sleep(check_interval)
            
            status_response = make_api_request_with_retry(
                url=f'https://api-inference.modelscope.cn/v1/tasks/{task_id}',
                headers={
                    'Authorization': f'Bearer {api_token}',
                    'X-ModelScope-Task-Type': 'image_generation'
                },
                method='get',
                timeout=int(config.get("timeout", 720))
            )
            
            if not status_response:
                continue
                
            if status_response.status_code != 200:
                continue
                
            status_data = status_response.json()
            status = status_data.get('task_status')
            
            if status == 'SUCCEED':
                output_images = status_data.get('output_images', [])
                if not output_images:
                    return None, "ä»»åŠ¡æˆåŠŸä½†æ— è¾“å‡ºå›¾åƒ"
                
                # ä¸‹è½½ç”Ÿæˆçš„å›¾ç‰‡
                img_url = output_images[0]
                img_response = requests.get(img_url, timeout=int(config.get("image_download_timeout", 30)))
                
                if img_response.status_code == 200:
                    img_data = BytesIO(img_response.content)
                    result_image = Image.open(img_data)
                    return result_image, f"å›¾åƒç”ŸæˆæˆåŠŸï¼ä»»åŠ¡ID: {task_id}"
                else:
                    return None, f"å›¾ç‰‡ä¸‹è½½å¤±è´¥: {img_response.status_code}"
            
            elif status == 'FAILED':
                error_info = status_data.get('errors', {})
                return None, f"ä»»åŠ¡å¤±è´¥: {error_info.get('message', 'Unknown error')}"
            
            elif status == 'PENDING' or status == 'RUNNING':
                continue
        
        return None, "ä»»åŠ¡è½®è¯¢è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•"
        
    except Exception as e:
        return None, f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"

# æ–‡æœ¬å¯¹è¯åŠŸèƒ½
def chat_with_model(message, history, api_token, model, system_prompt, max_tokens, temperature):
    if not OPENAI_AVAILABLE:
        return history + [{"role": "assistant", "content": "è¯·å…ˆå®‰è£…openaiåº“: pip install openai"}], ""
    
    config = load_config()
    
    if not api_token:
        return history + [{"role": "assistant", "content": "è¯·æä¾›æœ‰æ•ˆçš„API Token"}], ""
    
    if not message.strip():
        return history, ""
    
    try:
        client = OpenAI(
            base_url='https://api-inference.modelscope.cn/v1',
            api_key=api_token
        )
        
        # æ„å»ºæ¶ˆæ¯å†å²
        messages = [{"role": "system", "content": system_prompt}]
        
        # æ·»åŠ å†å²å¯¹è¯ï¼ˆä»messagesæ ¼å¼è½¬æ¢ï¼‰
        for msg in history:
            if isinstance(msg, dict) and "role" in msg and "content" in msg:
                if msg["role"] in ["user", "assistant"] and not msg["content"].startswith("ç³»ç»Ÿ"):
                    messages.append(msg)
        
        # æ·»åŠ å½“å‰æ¶ˆæ¯
        messages.append({"role": "user", "content": message})
        
        print(f"ğŸ’¬ å‘é€å¯¹è¯è¯·æ±‚ï¼Œæ¨¡å‹: {model}")
        
        response = client.chat.completions.create(
            model=model,
            messages=messages,
            max_tokens=max_tokens,
            temperature=temperature,
            stream=False
        )
        
        assistant_response = response.choices[0].message.content
        
        # æ›´æ–°å†å²è®°å½•ï¼ˆä½¿ç”¨messagesæ ¼å¼ï¼‰
        new_history = history + [
            {"role": "user", "content": message},
            {"role": "assistant", "content": assistant_response}
        ]
        
        return new_history, ""
        
    except Exception as e:
        error_msg = f"å¯¹è¯å¤±è´¥: {str(e)}"
        return history + [
            {"role": "user", "content": message},
            {"role": "assistant", "content": error_msg}
        ], ""

# å›¾ç”Ÿæ–‡åŠŸèƒ½
def analyze_image_with_text(image, prompt, api_token, model, max_tokens, temperature):
    if not OPENAI_AVAILABLE:
        return "è¯·å…ˆå®‰è£…openaiåº“: pip install openai"
    
    if not api_token:
        return "è¯·æä¾›æœ‰æ•ˆçš„API Token"
    
    if image is None:
        return "è¯·å…ˆä¸Šä¼ å›¾åƒ"
    
    try:
        print(f"ğŸ” å¼€å§‹åˆ†æå›¾åƒ...")
        print(f"ğŸ“ æç¤ºè¯: {prompt}")
        print(f"ğŸ¤– æ¨¡å‹: {model}")
        
        # è½¬æ¢å›¾åƒä¸ºbase64
        if hasattr(image, 'shape'):  # numpy array
            if image.max() <= 1.0:
                image_np = (image * 255).astype(np.uint8)
            else:
                image_np = image.astype(np.uint8)
            pil_image = Image.fromarray(image_np)
        else:  # PIL Image
            pil_image = image
        
        # ç¡®ä¿å›¾åƒæ˜¯RGBæ ¼å¼
        if pil_image.mode != 'RGB':
            pil_image = pil_image.convert('RGB')
        
        buffered = BytesIO()
        pil_image.save(buffered, format="JPEG", quality=85)
        img_base64 = base64.b64encode(buffered.getvalue()).decode('utf-8')
        image_url = f"data:image/jpeg;base64,{img_base64}"
        
        print(f"ğŸ–¼ï¸ å›¾åƒå·²è½¬æ¢ä¸ºbase64æ ¼å¼")
        
        client = OpenAI(
            base_url='https://api-inference.modelscope.cn/v1',
            api_key=api_token
        )
        
        messages = [{
            'role': 'user',
            'content': [{
                'type': 'text',
                'text': prompt,
            }, {
                'type': 'image_url',
                'image_url': {
                    'url': image_url,
                },
            }],
        }]
        
        print(f"ğŸš€ å‘é€APIè¯·æ±‚...")
        
        response = client.chat.completions.create(
            model=model,
            messages=messages,
            max_tokens=max_tokens,
            temperature=temperature,
            stream=False
        )
        
        description = response.choices[0].message.content
        print(f"âœ… åˆ†æå®Œæˆ!")
        print(f"ğŸ“„ ç»“æœ: {description[:100] if description else 'None'}...")
        
        if not description:
            return "APIè¿”å›äº†ç©ºçš„å“åº”ï¼Œè¯·æ£€æŸ¥æ¨¡å‹æ˜¯å¦æ”¯æŒå›¾åƒåˆ†æåŠŸèƒ½"
        
        return description
        
    except Exception as e:
        error_msg = f"å›¾åƒåˆ†æå¤±è´¥: {str(e)}"
        print(f"âŒ {error_msg}")
        return error_msg

# åˆ›å»ºGradioç•Œé¢
def create_gradio_interface():
    config = load_config()
    saved_token = load_api_token()  # åŠ è½½ä¿å­˜çš„token
    
    with gr.Blocks(title="ModelScope API WebUI", theme=gr.themes.Soft()) as demo:
        gr.Markdown("# ModelScope API WebUI")
        gr.Markdown("ä½¿ç”¨é­”æ­ModelScope APIè¿›è¡Œå›¾åƒç”Ÿæˆå’Œç¼–è¾‘")
        
        with gr.Tab("æ–‡ç”Ÿå›¾"):
            with gr.Row():
                with gr.Column(scale=1):
                    api_token_gen = gr.Textbox(
                        label="API Token",
                        placeholder="è¯·è¾“å…¥æ‚¨çš„ModelScope API Token",
                        type="password",
                        value=saved_token
                    )
                    save_token_gen = gr.Checkbox(
                        label="ä¿å­˜API Tokenåˆ°æœ¬åœ°åŠ å¯†æ–‡ä»¶",
                        value=bool(saved_token)
                    )
                    model_gen = gr.Dropdown(
                        label="æ¨¡å‹",
                        choices=config.get("image_models", ["Qwen/Qwen-Image"]),
                        value=config.get("default_model", "Qwen/Qwen-Image")
                    )
                    prompt_gen = gr.Textbox(
                        label="æç¤ºè¯",
                        placeholder="è¯·è¾“å…¥å›¾åƒæè¿°",
                        value=config.get("default_prompt", "A beautiful landscape"),
                        lines=3
                    )
                    negative_prompt_gen = gr.Textbox(
                        label="è´Ÿé¢æç¤ºè¯",
                        placeholder="ä¸å¸Œæœ›å‡ºç°åœ¨å›¾åƒä¸­çš„å†…å®¹",
                        value=config.get("default_negative_prompt", ""),
                        lines=2
                    )
                    
                    with gr.Row():
                        width_gen = gr.Slider(label="å®½åº¦", minimum=256, maximum=2048, value=config.get("default_width", 512), step=64)
                        height_gen = gr.Slider(label="é«˜åº¦", minimum=256, maximum=2048, value=config.get("default_height", 512), step=64)
                    
                    with gr.Row():
                        steps_gen = gr.Slider(label="æ­¥æ•°", minimum=1, maximum=100, value=config.get("default_steps", 30), step=1)
                        guidance_gen = gr.Slider(label="å¼•å¯¼ç³»æ•°", minimum=1.0, maximum=20.0, value=config.get("default_guidance", 7.5), step=0.1)
                        seed_gen = gr.Number(label="éšæœºç§å­", value=config.get("default_seed", -1))
                
                with gr.Column(scale=1):
                    output_image_gen = gr.Image(label="ç”Ÿæˆç»“æœ", type="pil")
                    output_message_gen = gr.Textbox(label="è¾“å‡ºä¿¡æ¯", interactive=False)
                    gen_btn = gr.Button("ç”Ÿæˆå›¾åƒ", variant="primary")
        
        with gr.Tab("å›¾åƒç¼–è¾‘"):
            with gr.Row():
                with gr.Column(scale=1):
                    api_token_edit = gr.Textbox(
                        label="API Token",
                        placeholder="è¯·è¾“å…¥æ‚¨çš„ModelScope API Token",
                        type="password",
                        value=saved_token
                    )
                    save_token_edit = gr.Checkbox(
                        label="ä¿å­˜API Tokenåˆ°æœ¬åœ°åŠ å¯†æ–‡ä»¶",
                        value=bool(saved_token)
                    )
                    model_edit = gr.Dropdown(
                        label="æ¨¡å‹",
                        choices=config.get("image_edit_models", ["Qwen/Qwen-Image-Edit"]),
                        value=config.get("image_edit_models", ["Qwen/Qwen-Image-Edit"])[0] if config.get("image_edit_models") else "Qwen/Qwen-Image-Edit"
                    )
                    input_image_edit = gr.Image(label="è¾“å…¥å›¾åƒ", type="pil")
                    input_image_info_edit = gr.Textbox(label="è¾“å…¥å›¾åƒä¿¡æ¯", interactive=False, visible=False)
                    prompt_edit = gr.Textbox(
                        label="æç¤ºè¯",
                        placeholder="è¯·è¾“å…¥å›¾åƒç¼–è¾‘æè¿°",
                        value="ä¿®æ”¹å›¾ç‰‡ä¸­çš„å†…å®¹",
                        lines=3
                    )
                    negative_prompt_edit = gr.Textbox(
                        label="è´Ÿé¢æç¤ºè¯",
                        placeholder="ä¸å¸Œæœ›å‡ºç°åœ¨å›¾åƒä¸­çš„å†…å®¹",
                        value=config.get("default_negative_prompt", ""),
                        lines=2
                    )
                    
                    adaptive_ratio_edit = gr.Checkbox(
                        label="è‡ªé€‚åº”åŸå›¾æ¯”ä¾‹",
                        value=True,
                        info="å‹¾é€‰ååªéœ€è°ƒæ•´é•¿è¾¹å°ºå¯¸ï¼Œè‡ªåŠ¨ä¿æŒåŸå›¾æ¯”ä¾‹"
                    )
                    
                    with gr.Row():
                        with gr.Column(visible=False) as manual_size_edit:
                            width_edit = gr.Slider(label="å®½åº¦", minimum=256, maximum=2048, value=config.get("default_width", 512), step=64)
                            height_edit = gr.Slider(label="é«˜åº¦", minimum=256, maximum=2048, value=config.get("default_height", 512), step=64)
                        
                        with gr.Column(visible=True) as adaptive_size_edit:
                            long_edge_edit = gr.Slider(label="é•¿è¾¹å°ºå¯¸", minimum=256, maximum=2048, value=1024, step=64, info="å›¾åƒé•¿è¾¹çš„åƒç´ å°ºå¯¸ï¼ŒçŸ­è¾¹ä¼šè‡ªåŠ¨æŒ‰åŸå›¾æ¯”ä¾‹è®¡ç®—")
                    
                    with gr.Row():
                        steps_edit = gr.Slider(label="æ­¥æ•°", minimum=1, maximum=100, value=config.get("default_steps", 30), step=1)
                        guidance_edit = gr.Slider(label="å¼•å¯¼ç³»æ•°", minimum=1.0, maximum=20.0, value=config.get("default_guidance", 7.5), step=0.1)
                        seed_edit = gr.Number(label="éšæœºç§å­", value=config.get("default_seed", -1))
                
                with gr.Column(scale=1):
                    output_image_edit = gr.Image(label="ç¼–è¾‘ç»“æœ", type="pil")
                    output_message_edit = gr.Textbox(label="è¾“å‡ºä¿¡æ¯", interactive=False)
                    edit_btn = gr.Button("ç¼–è¾‘å›¾åƒ", variant="primary")
        
        with gr.Tab("æ–‡æœ¬å¯¹è¯"):
            with gr.Row():
                with gr.Column(scale=1):
                    api_token_chat = gr.Textbox(
                        label="API Token",
                        placeholder="è¯·è¾“å…¥æ‚¨çš„ModelScope API Token",
                        type="password",
                        value=saved_token
                    )
                    save_token_chat = gr.Checkbox(
                        label="ä¿å­˜API Tokenåˆ°æœ¬åœ°åŠ å¯†æ–‡ä»¶",
                        value=bool(saved_token)
                    )
                    model_chat = gr.Dropdown(
                        label="æ¨¡å‹",
                        choices=config.get("text_models", ["Qwen/Qwen3-Coder-480B-A35B-Instruct"]),
                        value=config.get("default_text_model", "Qwen/Qwen3-Coder-480B-A35B-Instruct")
                    )
                    system_prompt_chat = gr.Textbox(
                        label="ç³»ç»Ÿæç¤ºè¯",
                        placeholder="è®¾ç½®AIçš„è§’è‰²å’Œè¡Œä¸º",
                        value=config.get("default_system_prompt", "You are a helpful assistant."),
                        lines=2
                    )
                    
                    with gr.Row():
                        max_tokens_chat = gr.Slider(label="æœ€å¤§Tokenæ•°", minimum=100, maximum=8000, value=2000, step=100)
                        temperature_chat = gr.Slider(label="æ¸©åº¦", minimum=0.1, maximum=2.0, value=0.7, step=0.1)
                
                with gr.Column(scale=2):
                    chatbot = gr.Chatbot(label="å¯¹è¯å†å²", height=400, type="messages")
                    msg = gr.Textbox(label="è¾“å…¥æ¶ˆæ¯", placeholder="è¯·è¾“å…¥æ‚¨çš„é—®é¢˜...", lines=2)
                    with gr.Row():
                        submit_btn = gr.Button("å‘é€", variant="primary")
                        clear_btn = gr.Button("æ¸…ç©ºå¯¹è¯")
        
        with gr.Tab("å›¾ç”Ÿæ–‡"):
            with gr.Row():
                with gr.Column(scale=1):
                    api_token_vision = gr.Textbox(
                        label="API Token",
                        placeholder="è¯·è¾“å…¥æ‚¨çš„ModelScope API Token",
                        type="password",
                        value=saved_token
                    )
                    save_token_vision = gr.Checkbox(
                        label="ä¿å­˜API Tokenåˆ°æœ¬åœ°åŠ å¯†æ–‡ä»¶",
                        value=bool(saved_token)
                    )
                    model_vision = gr.Dropdown(
                        label="æ¨¡å‹",
                        choices=config.get("vision_models", ["stepfun-ai/step3"]),
                        value=config.get("vision_models", ["stepfun-ai/step3"])[0] if config.get("vision_models") else "stepfun-ai/step3"
                    )
                    input_image_vision = gr.Image(label="è¾“å…¥å›¾åƒ", type="pil")
                    input_image_info_vision = gr.Textbox(label="è¾“å…¥å›¾åƒä¿¡æ¯", interactive=False, visible=False)
                    prompt_vision = gr.Textbox(
                        label="æç¤ºè¯",
                        placeholder="è¯·è¾“å…¥æ‚¨æƒ³äº†è§£å›¾åƒçš„ä»€ä¹ˆä¿¡æ¯",
                        value="è¯·è¯¦ç»†æè¿°è¿™å¹…å›¾åƒçš„å†…å®¹",
                        lines=3
                    )
                    
                    with gr.Row():
                        max_tokens_vision = gr.Slider(label="æœ€å¤§Tokenæ•°", minimum=100, maximum=4000, value=1000, step=100)
                        temperature_vision = gr.Slider(label="æ¸©åº¦", minimum=0.1, maximum=2.0, value=0.7, step=0.1)
                
                with gr.Column(scale=1):
                    output_text_vision = gr.Textbox(label="å›¾åƒæè¿°", lines=15, interactive=False)
                    analyze_btn = gr.Button("åˆ†æå›¾åƒ", variant="primary")
        
        # API Tokenä¿å­˜å¤„ç†å‡½æ•°
        def handle_token_save(token, should_save):
            if should_save and token and token.strip():
                success = save_api_token(token)
                if success:
                    return "âœ… API Tokenå·²ä¿å­˜åˆ°æœ¬åœ°åŠ å¯†æ–‡ä»¶"
                else:
                    return "âŒ API Tokenä¿å­˜å¤±è´¥"
            elif not should_save:
                delete_api_token()
                return "ğŸ—‘ï¸ API Tokenå·²åˆ é™¤"
            else:
                return ""
        
        # ç•Œé¢åˆ‡æ¢é€»è¾‘
        def toggle_size_controls(adaptive_ratio):
            if adaptive_ratio:
                return gr.update(visible=False), gr.update(visible=True)
            else:
                return gr.update(visible=True), gr.update(visible=False)
        
        adaptive_ratio_edit.change(
            fn=toggle_size_controls,
            inputs=[adaptive_ratio_edit],
            outputs=[manual_size_edit, adaptive_size_edit]
        )
        
        # å›¾åƒå°ºå¯¸æ˜¾ç¤ºäº‹ä»¶
        def update_image_info(image):
            if image is None:
                return gr.update(visible=False), ""
            else:
                info = get_image_info(image)
                return gr.update(visible=True), info
        
        # æ·»åŠ çŠ¶æ€æ˜¾ç¤ºç»„ä»¶
        with gr.Row():
            token_status = gr.Textbox(label="TokençŠ¶æ€", interactive=False, visible=False)
        
        # API Tokenä¿å­˜äº‹ä»¶ç»‘å®š
        save_token_gen.change(
            fn=handle_token_save,
            inputs=[api_token_gen, save_token_gen],
            outputs=[token_status]
        )
        
        save_token_edit.change(
            fn=handle_token_save,
            inputs=[api_token_edit, save_token_edit],
            outputs=[token_status]
        )
        
        save_token_chat.change(
            fn=handle_token_save,
            inputs=[api_token_chat, save_token_chat],
            outputs=[token_status]
        )
        
        save_token_vision.change(
            fn=handle_token_save,
            inputs=[api_token_vision, save_token_vision],
            outputs=[token_status]
        )
        
        # ç»‘å®šäº‹ä»¶
        gen_btn.click(
            fn=generate_image,
            inputs=[api_token_gen, model_gen, prompt_gen, negative_prompt_gen, width_gen, height_gen, steps_gen, guidance_gen, seed_gen],
            outputs=[output_image_gen, output_message_gen]
        )
        
        edit_btn.click(
            fn=edit_image,
            inputs=[api_token_edit, model_edit, input_image_edit, prompt_edit, negative_prompt_edit, adaptive_ratio_edit, width_edit, height_edit, long_edge_edit, steps_edit, guidance_edit, seed_edit],
            outputs=[output_image_edit, output_message_edit]
        )
        
        # è¾“å…¥å›¾åƒå˜åŒ–æ—¶æ˜¾ç¤ºå°ºå¯¸ä¿¡æ¯
        input_image_edit.change(
            fn=update_image_info,
            inputs=[input_image_edit],
            outputs=[input_image_info_edit, input_image_info_edit]
        )
        
        input_image_vision.change(
            fn=update_image_info,
            inputs=[input_image_vision],
            outputs=[input_image_info_vision, input_image_info_vision]
        )
        
        # æ–‡æœ¬å¯¹è¯äº‹ä»¶ç»‘å®š
        def clear_chat():
            return [], ""
        
        submit_btn.click(
            fn=chat_with_model,
            inputs=[msg, chatbot, api_token_chat, model_chat, system_prompt_chat, max_tokens_chat, temperature_chat],
            outputs=[chatbot, msg]
        )
        
        msg.submit(
            fn=chat_with_model,
            inputs=[msg, chatbot, api_token_chat, model_chat, system_prompt_chat, max_tokens_chat, temperature_chat],
            outputs=[chatbot, msg]
        )
        
        clear_btn.click(
            fn=clear_chat,
            outputs=[chatbot, msg]
        )
        
        # å›¾ç”Ÿæ–‡äº‹ä»¶ç»‘å®š
        analyze_btn.click(
            fn=analyze_image_with_text,
            inputs=[input_image_vision, prompt_vision, api_token_vision, model_vision, max_tokens_vision, temperature_vision],
            outputs=[output_text_vision]
        )
        
        # æ·»åŠ ç®€å•çš„JavaScriptä»£ç ç”¨äºç•Œé¢å¢å¼º
        demo.load(js="""
        function() {
            console.log('ModelScope API WebUI loaded');
            
            // æ·»åŠ ä¸€äº›ç•Œé¢å¢å¼ºåŠŸèƒ½
            setTimeout(function() {
                // ä¸ºæ‰€æœ‰æŒ‰é’®æ·»åŠ åŠ è½½çŠ¶æ€æ ·å¼
                const buttons = document.querySelectorAll('button');
                buttons.forEach(button => {
                    button.addEventListener('click', function() {
                        if (this.textContent.includes('ç”Ÿæˆ') || this.textContent.includes('ç¼–è¾‘') || this.textContent.includes('åˆ†æ')) {
                            this.style.opacity = '0.7';
                            setTimeout(() => {
                                this.style.opacity = '1';
                            }, 1000);
                        }
                    });
                });
            }, 1000);
        }
        """)
    
    return demo

if __name__ == "__main__":
    demo = create_gradio_interface()
    demo.launch(server_name="0.0.0.0", server_port=7860, share=False)